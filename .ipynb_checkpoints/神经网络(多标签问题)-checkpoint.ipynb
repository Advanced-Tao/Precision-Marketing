{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class market():\n",
    "    def word_cut(self,documents):\n",
    "        stopwords = self.stopwords\n",
    "        import jieba\n",
    "        texts = []\n",
    "        for line in documents:\n",
    "            words = ' '.join(jieba.cut(line)).split(' ') # 用空格去连接，连接后马上又拆分\n",
    "            text = []\n",
    "            for word in words:\n",
    "                if (word not in stopwords) & (word != '')& (word != '\\u3000')& (word != '\\n')&(word != '\\u200b'):\n",
    "                    text.append(word)\n",
    "            texts.append(text)\n",
    "        self.docLength = len(documents)\n",
    "        return(texts)\n",
    "    def get_docLength(self):\n",
    "        return(self.docLength)\n",
    "    def frequency(self,texts,freq):\n",
    "        from collections import defaultdict\n",
    "        frequency = defaultdict(int) # value为int\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                frequency[word] += 1\n",
    "        texts = [[word for word in text if frequency[word] > freq] for text in texts]\n",
    "        return(texts)\n",
    "    def regroup(self,texts):\n",
    "        new_texts = []\n",
    "        for i,sentence in enumerate(texts):\n",
    "            new_texts.append(\" \".join(sentence))\n",
    "        return(new_texts)\n",
    "    def add_stopwords(self,path):\n",
    "        stopwords = set()\n",
    "        with open(path,'r',encoding = 'cp936') as file:\n",
    "            for line in file:\n",
    "                stopwords.add(line.strip())\n",
    "        self.stopwords = stopwords\n",
    "        print(\"Load %s stopwords\" %len(stopwords))\n",
    "    def dictionary(self,docs):\n",
    "        token_index ={}\n",
    "        for sample in docs:\n",
    "            for word in sample:\n",
    "                if word not in token_index:\n",
    "                    token_index[word] = len(token_index) + 1\n",
    "        return(token_index)\n",
    "    def count(self,docs):\n",
    "        token_length ={}\n",
    "        for sample in docs:\n",
    "            for word in sample:\n",
    "                if word not in token_length:\n",
    "                    token_length[word] = 1\n",
    "                else:\n",
    "                    token_length[word] += 1\n",
    "        return(token_length)\n",
    "    def recoding(self,docs,token_index):\n",
    "        for i,sample in enumerate(docs):\n",
    "            for j,word in enumerate(sample):\n",
    "                if word not in token_index:\n",
    "                    sample[j] = -1\n",
    "                else:\n",
    "                    sample[j] = token_index[word]\n",
    "            docs[i] = sample\n",
    "        return(docs)\n",
    "    def delete(self,docs):\n",
    "        for index in range(len(docs)):\n",
    "            for i in range(len(docs[index])-1,-1,-1):\n",
    "                if docs[index][i] == -1:\n",
    "                    docs[index].pop(i)\n",
    "        return docs\n",
    "    def random_pick(self,df,n):\n",
    "        import random\n",
    "        import numpy as np\n",
    "        rand = np.arange(0,(len(df)-1),1)\n",
    "        random.shuffle(rand)\n",
    "        rand = list(rand[:n])\n",
    "        df = df.loc[rand,]\n",
    "        return(df)\n",
    "    def read_vectors(self,path, topn):  # read top n word vectors, i.e. top is 10000\n",
    "        lines_num, dim = 0, 0\n",
    "        vectors = {}\n",
    "        iw = []\n",
    "        wi = {}\n",
    "        with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "            first_line = True\n",
    "            for line in f:\n",
    "                if first_line:\n",
    "                    first_line = False\n",
    "                    dim = int(line.rstrip().split()[1]) # 删除向量末尾的空格，然后以空格拆分获得向量\n",
    "                    continue\n",
    "                lines_num += 1\n",
    "                tokens = line.rstrip().split(' ')\n",
    "                vectors[tokens[0]] = np.asarray([float(x) for x in tokens[1:]])# 当数据源是ndarray时，asarray不会占用新的内存；当数据源不是ndarray,asarray与array一样\n",
    "                iw.append(tokens[0]) # iw储存了所有的tokons[0]，意思是index_word\n",
    "                if topn != 0 and lines_num >= topn:\n",
    "                    break\n",
    "        for i, w in enumerate(iw):\n",
    "            wi[w] = i # wi是iw的反转，意思是word_index,用w来储存字符，用一个integer去给字符编码\n",
    "        self.dim = dim\n",
    "        self.max_words = topn\n",
    "        self.word_index = wi\n",
    "        self.index_word = iw\n",
    "        self.vectors = vectors\n",
    "        print(\"Load %s word vectors.\" % len(vectors))\n",
    "    def embedding_matrix(self):\n",
    "        embedding_matrix = np.zeros((self.max_words,self.dim))\n",
    "        for word,i in self.word_index.items():\n",
    "            if i < self.max_words:\n",
    "                embedding_vector = self.vectors.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    def navie_knn(self,dataSet, query, k):  \n",
    "        # 计算出某一样本与所有样本的距离，选择最大(应该修改为最小？)的k个样本作为用于knn\n",
    "        numSamples = dataSet.shape[0] # return row(sample) number of dataset\n",
    "\n",
    "        ## step 1: calculate Euclidean distance  \n",
    "        diff = np.tile(query, (numSamples, 1)) - dataSet #tile: 把query这个向量纵向复制，使得结果与dataset具有同样的行数\n",
    "        squaredDiff = diff ** 2  \n",
    "        squaredDist = np.sum(squaredDiff, axis = 1) # sum is performed by row  \n",
    "\n",
    "        ## step 2: sort the distance  \n",
    "        sortedDistIndices = np.argsort(squaredDist)   # numpy.argsort 返回的是数组值从小到大的索引值（注意是索引值，不是绝对值）\n",
    "        if k > len(sortedDistIndices):  \n",
    "            k = len(sortedDistIndices)  \n",
    "\n",
    "        return sortedDistIndices[0:k]\n",
    "    # build a big graph (normalized weight matrix)  \n",
    "    def buildGraph(self,MatX, kernel_type, rbf_sigma = None, knn_num_neighbors = None):  \n",
    "        num_samples = MatX.shape[0]  # return row(sample) number of MatX\n",
    "        affinity_matrix = np.zeros((num_samples, num_samples), np.float32)  \n",
    "        if kernel_type == 'rbf':  \n",
    "            if rbf_sigma == None:  \n",
    "                raise ValueError('You should input a sigma of rbf kernel!')  \n",
    "            for i in range(num_samples):  \n",
    "                row_sum = 0.0  \n",
    "                for j in range(num_samples):  \n",
    "                    diff = MatX[i, :] - MatX[j, :]  \n",
    "                    affinity_matrix[i][j] = np.exp(sum(diff**2) / (-2.0 * rbf_sigma**2))  \n",
    "                    row_sum += affinity_matrix[i][j]  \n",
    "                affinity_matrix[i][:] /= row_sum  \n",
    "        elif kernel_type == 'knn':  \n",
    "            if knn_num_neighbors == None:  \n",
    "                raise ValueError('You should input a k of knn kernel!')  \n",
    "            for i in range(num_samples):  \n",
    "                k_neighbors = self.navie_knn(MatX, MatX[i, :], knn_num_neighbors)  \n",
    "                affinity_matrix[i][k_neighbors] = 1.0 / knn_num_neighbors  # 将节点i与附近的k个节点连接起来，每个边的权重是1/knn_num_neighbors\n",
    "        else:  \n",
    "            raise NameError('Not support kernel type! You can use knn or rbf!')  \n",
    "\n",
    "        return affinity_matrix  \n",
    "    # label propagation  \n",
    "    def labelPropagation(self,Mat_Label, Mat_Unlabel, labels, kernel_type = 'rbf', rbf_sigma = 0.20, \\\n",
    "                        knn_num_neighbors = 10, max_iter = 500, tol = 1e-3):  \n",
    "        # initialize  \n",
    "        num_label_samples = Mat_Label.shape[0]  #已经标记的sample number\n",
    "        num_unlabel_samples = Mat_Unlabel.shape[0]  #未标记的sample number\n",
    "        num_samples = num_label_samples + num_unlabel_samples\n",
    "        labels_list = np.unique(labels)  #有哪些label\n",
    "        num_classes = len(labels_list)  #label的种类数\n",
    "\n",
    "        MatX = np.vstack((Mat_Label, Mat_Unlabel))\n",
    "        clamp_data_label = np.zeros((num_label_samples, num_classes), np.float32)  \n",
    "        for i in range(num_label_samples):  \n",
    "            clamp_data_label[i][labels[i]] = 1.0   #标记出每一个labelled sample的具体label是什么\n",
    "\n",
    "        label_function = np.zeros((num_samples, num_classes), np.float32)  \n",
    "        label_function[0 : num_label_samples] = clamp_data_label  \n",
    "        label_function[num_label_samples : num_samples] = -1  \n",
    "\n",
    "        # graph construction  \n",
    "        affinity_matrix = self.buildGraph(MatX, kernel_type, rbf_sigma, knn_num_neighbors)  \n",
    "\n",
    "        # start to propagation  \n",
    "        iter = 0; pre_label_function = np.zeros((num_samples, num_classes), np.float32)  \n",
    "        changed = np.abs(pre_label_function - label_function).sum()  \n",
    "        while iter < max_iter and changed > tol:  \n",
    "            if iter % 1 == 0:  \n",
    "                print (\"---> Iteration %d/%d, changed: %f\" % (iter, max_iter, changed))\n",
    "            pre_label_function = label_function  \n",
    "            iter += 1  \n",
    "\n",
    "            # propagation  \n",
    "            label_function = np.dot(affinity_matrix, label_function)  \n",
    "\n",
    "            # clamp  \n",
    "            label_function[0 : num_label_samples] = clamp_data_label  \n",
    "\n",
    "            # check converge  \n",
    "            changed = np.abs(pre_label_function - label_function).sum()  \n",
    "\n",
    "        # get terminate label of unlabeled data  \n",
    "        unlabel_data_labels = np.zeros(num_unlabel_samples)  \n",
    "        for i in range(num_unlabel_samples):  \n",
    "            unlabel_data_labels[i] = np.argmax(label_function[i+num_label_samples]) #取出参数中元素最大值所对应的索引 \n",
    "\n",
    "        return unlabel_data_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 2316 stopwords\n",
      "Load 20000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "process = market()\n",
    "process.add_stopwords(\"D:/Users/PYTHON/Precision-Marketing/stopwords.txt\")\n",
    "process.read_vectors(\"D:/NLP/sgns.target.word-word.dynwin5.thr10.neg5.dim300.txt\",20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = process.embedding_matrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经读取第0个sheet\n",
      "已经读取第1个sheet\n",
      "已经读取第2个sheet\n",
      "已经读取第3个sheet\n",
      "已经读取第4个sheet\n",
      "已经读取第5个sheet\n",
      "已经读取第6个sheet\n",
      "已经读取第7个sheet\n",
      "已经读取第8个sheet\n",
      "已经读取第9个sheet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户名</th>\n",
       "      <th>博文</th>\n",
       "      <th>关键词</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "      <th>标签1（担忧对象）</th>\n",
       "      <th>标签2（担忧什么）</th>\n",
       "      <th>标签3（什么保险）</th>\n",
       "      <th>标签4（症状）</th>\n",
       "      <th>转发数</th>\n",
       "      <th>评论数</th>\n",
       "      <th>点赞数</th>\n",
       "      <th>发文时间</th>\n",
       "      <th>来自</th>\n",
       "      <th>页面网址</th>\n",
       "      <th>博文链接</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1杯冰牛奶</td>\n",
       "      <td>\\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天06:16\\n           ...</td>\n",
       "      <td>iPhone 11</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/6606022745/IwQhN1EAC?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>干杯老铁</td>\n",
       "      <td>\\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天06:02\\n           ...</td>\n",
       "      <td>即刻笔记</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/3394404550/IwQbUFIBq?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>分手挽回失恋复合前男友前任导师</td>\n",
       "      <td>\\n                    #分手了怎么挽回前任##失恋后怎么挽回前任# 父...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天03:39\\n           ...</td>\n",
       "      <td>微博 weibo.com</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/3984809099/IwPfZfAGM?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>全球奇葩事</td>\n",
       "      <td>\\n                    网友投稿：小孩子一岁多，打了媳妇几下，媳妇就教育...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n                        今天02:11\\n           ...</td>\n",
       "      <td>微博 weibo.com</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/5629436483/IwOGmd1HG?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>肆意放纵野蛮生长</td>\n",
       "      <td>\\n                    抑郁症我有慢性疾病，怎么治都治不好，可是我才1...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>1.0</td>\n",
       "      <td>父母</td>\n",
       "      <td>经济</td>\n",
       "      <td>死亡保险</td>\n",
       "      <td>情绪问题</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天01:18\\n           ...</td>\n",
       "      <td>抑郁症超话</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/6087910635/IwOkWv6iP?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>永远玩不到王者的6公子</td>\n",
       "      <td>\\n                    第123件关于我们的回忆：接上条继续...有次带...</td>\n",
       "      <td>不舒服会不会</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        2019年12月28日 22:49\\n ...</td>\n",
       "      <td>iPhone客户端</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...</td>\n",
       "      <td>https://weibo.com/6397021518/ImUA07X1Z?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>泥销白骨</td>\n",
       "      <td>\\n                    有点get到这个教官了 虽然早上觉得呆板无趣但其...</td>\n",
       "      <td>不舒服会不会</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        2019年12月28日 22:25\\n ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...</td>\n",
       "      <td>https://weibo.com/1837879215/ImUqrEiBB?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>很喜欢舔酸奶盖</td>\n",
       "      <td>\\n                    没有体验过，会不会不舒服啊           ...</td>\n",
       "      <td>不舒服会不会</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019年12月28日 19:34</td>\n",
       "      <td>Android</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...</td>\n",
       "      <td>https://weibo.com/2825646441/ImTiNCq49?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>魔鬼管理学</td>\n",
       "      <td>职场中，学习能力要比学历重要的多。\\n\\n每一条都是曾经打在自己身上的鞭子，条条带血。\\n\\...</td>\n",
       "      <td>不舒服会不会</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>\\n                        2019年12月28日 21:40\\n ...</td>\n",
       "      <td>荣耀 9X</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...</td>\n",
       "      <td>https://weibo.com/2406560131/ImU7Ue32T?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>bikkiu</td>\n",
       "      <td>\\n                    每天都在担心本本会不会不舒服啥的，我真是个好麻麻...</td>\n",
       "      <td>不舒服会不会</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        2019年12月28日 21:38\\n ...</td>\n",
       "      <td>iPhone客户端</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...</td>\n",
       "      <td>https://weibo.com/7166843130/ImU7fppSo?refer_f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1576 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 用户名                                                 博文  \\\n",
       "0              1杯冰牛奶  \\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...   \n",
       "1               干杯老铁  \\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...   \n",
       "2    分手挽回失恋复合前男友前任导师  \\n                    #分手了怎么挽回前任##失恋后怎么挽回前任# 父...   \n",
       "3              全球奇葩事  \\n                    网友投稿：小孩子一岁多，打了媳妇几下，媳妇就教育...   \n",
       "4           肆意放纵野蛮生长  \\n                    抑郁症我有慢性疾病，怎么治都治不好，可是我才1...   \n",
       "..               ...                                                ...   \n",
       "195      永远玩不到王者的6公子  \\n                    第123件关于我们的回忆：接上条继续...有次带...   \n",
       "196             泥销白骨  \\n                    有点get到这个教官了 虽然早上觉得呆板无趣但其...   \n",
       "197          很喜欢舔酸奶盖  \\n                    没有体验过，会不会不舒服啊           ...   \n",
       "198            魔鬼管理学  职场中，学习能力要比学历重要的多。\\n\\n每一条都是曾经打在自己身上的鞭子，条条带血。\\n\\...   \n",
       "199           bikkiu  \\n                    每天都在担心本本会不会不舒服啥的，我真是个好麻麻...   \n",
       "\n",
       "        关键词  是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症） 标签1（担忧对象） 标签2（担忧什么）  \\\n",
       "0     父母怎么办                                         -1.0       NaN       NaN   \n",
       "1     父母怎么办                                          0.0       NaN       NaN   \n",
       "2     父母怎么办                                         -1.0       NaN       NaN   \n",
       "3     父母怎么办                                          0.0       NaN       NaN   \n",
       "4     父母怎么办                                          1.0        父母        经济   \n",
       "..      ...                                          ...       ...       ...   \n",
       "195  不舒服会不会                                         -1.0       NaN       NaN   \n",
       "196  不舒服会不会                                         -1.0       NaN       NaN   \n",
       "197  不舒服会不会                                         -1.0       NaN       NaN   \n",
       "198  不舒服会不会                                         -1.0       NaN       NaN   \n",
       "199  不舒服会不会                                         -1.0       NaN       NaN   \n",
       "\n",
       "    标签3（什么保险） 标签4（症状）  转发数 评论数 点赞数  \\\n",
       "0         NaN     NaN                \n",
       "1         NaN     NaN                \n",
       "2         NaN     NaN                \n",
       "3         NaN     NaN    1   3   2   \n",
       "4        死亡保险    情绪问题        8       \n",
       "..        ...     ...  ...  ..  ..   \n",
       "195       NaN     NaN                \n",
       "196       NaN     NaN                \n",
       "197       NaN     NaN                \n",
       "198       NaN     NaN  111   6  74   \n",
       "199       NaN     NaN                \n",
       "\n",
       "                                                  发文时间            来自  \\\n",
       "0    \\n                        今天06:16\\n           ...     iPhone 11   \n",
       "1    \\n                        今天06:02\\n           ...          即刻笔记   \n",
       "2    \\n                        今天03:39\\n           ...  微博 weibo.com   \n",
       "3    \\n                        今天02:11\\n           ...  微博 weibo.com   \n",
       "4    \\n                        今天01:18\\n           ...         抑郁症超话   \n",
       "..                                                 ...           ...   \n",
       "195  \\n                        2019年12月28日 22:49\\n ...     iPhone客户端   \n",
       "196  \\n                        2019年12月28日 22:25\\n ...           NaN   \n",
       "197                                  2019年12月28日 19:34       Android   \n",
       "198  \\n                        2019年12月28日 21:40\\n ...         荣耀 9X   \n",
       "199  \\n                        2019年12月28日 21:38\\n ...     iPhone客户端   \n",
       "\n",
       "                                                  页面网址  \\\n",
       "0    https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "1    https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "2    https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "3    https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "4    https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "..                                                 ...   \n",
       "195  https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...   \n",
       "196  https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...   \n",
       "197  https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...   \n",
       "198  https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...   \n",
       "199  https://s.weibo.com/weibo/%25E4%25B8%258D%25E8...   \n",
       "\n",
       "                                                  博文链接  \n",
       "0    https://weibo.com/6606022745/IwQhN1EAC?refer_f...  \n",
       "1    https://weibo.com/3394404550/IwQbUFIBq?refer_f...  \n",
       "2    https://weibo.com/3984809099/IwPfZfAGM?refer_f...  \n",
       "3    https://weibo.com/5629436483/IwOGmd1HG?refer_f...  \n",
       "4    https://weibo.com/6087910635/IwOkWv6iP?refer_f...  \n",
       "..                                                 ...  \n",
       "195  https://weibo.com/6397021518/ImUA07X1Z?refer_f...  \n",
       "196  https://weibo.com/1837879215/ImUqrEiBB?refer_f...  \n",
       "197  https://weibo.com/2825646441/ImTiNCq49?refer_f...  \n",
       "198  https://weibo.com/2406560131/ImU7Ue32T?refer_f...  \n",
       "199  https://weibo.com/7166843130/ImU7fppSo?refer_f...  \n",
       "\n",
       "[1576 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"D:/Users/PYTHON/Precision-Marketing\")\n",
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    print(\"已经读取第{}个sheet\".format(i))\n",
    "    df_temp = pd.read_excel(\"关键词标签.xlsx\",sheet_name = i)\n",
    "    df = df.append(df_temp)\n",
    "# PATIENT = PATIENT[[\"博文\",\"是否担忧（1=担忧，0=不担忧）\",\"标签1（担忧对象）\",\"标签2（担忧什么）\",\"标签3（什么保险）\",\"标签4（症状）\"]]\n",
    "# PATIENT = PATIENT.loc[pd.notna(PATIENT[\"是否担忧（1=担忧，0=不担忧）\"]),]\n",
    "# PATIENT = PATIENT.fillna(\"无\") # 可以尝试将是否担忧作为一个feature！\n",
    "# PATIENT.head(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文  \\\n",
       "0  \\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...   \n",
       "1  \\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...   \n",
       "\n",
       "   是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "0                                         -1.0  \n",
       "1                                          0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[pd.notna(df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]),[\"博文\",\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]]\n",
    "# df = df.fillna(\"无\") # 可以尝试将是否担忧作为一个feature！\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...</td>\n",
       "      <td>中性</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文  \\\n",
       "0  \\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...   \n",
       "1  \\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...   \n",
       "\n",
       "  是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "0                                         不担忧  \n",
       "1                                          中性  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda v: \"担忧\" if v == 1 else (\"中性\" if v == 0 else (\"不担忧\" if v == -1 else \"疑似抑郁症\"))\n",
    "\n",
    "df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] = df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"].astype(\"int\") # float转化为int\n",
    "df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] = df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"].apply(f)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1574\n",
      "1574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...</td>\n",
       "      <td>中性</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文  \\\n",
       "0  \\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...   \n",
       "1  \\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...   \n",
       "\n",
       "  是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "0                                         不担忧  \n",
       "1                                          中性  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.concat([PATIENT]) # concat之后row index会重复\n",
    "# df = pd.concat([PATIENT])\n",
    "df.reset_index(drop = True,inplace = True)\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "不担忧      942\n",
       "担忧       327\n",
       "中性       296\n",
       "疑似抑郁症      9\n",
       "Name: 是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "df_worry = df[df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] == \"担忧\"]\n",
    "df_worry.reset_index(drop = True,inplace = True)\n",
    "df_non_worry = df[df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] == \"不担忧\"]\n",
    "df_non_worry.reset_index(drop = True,inplace = True)\n",
    "df_notso_worry = df[df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] == \"中性\"]\n",
    "df_notso_worry.reset_index(drop = True,inplace = True)\n",
    "df_non_worry = process.random_pick(df_non_worry,min(len(df_worry),len(df_non_worry)))\n",
    "print(len(df_worry))\n",
    "print(len(df_non_worry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "df_worry = df_worry.dropna()\n",
    "df_non_worry = df_non_worry.dropna()\n",
    "print(len(df_worry))\n",
    "print(len(df_non_worry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>\\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>\\n                    #天气与心情# 2月14曰，这天大家应该都记得，...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    博文  \\\n",
       "420  \\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...   \n",
       "448  \\n                    #天气与心情# 2月14曰，这天大家应该都记得，...   \n",
       "\n",
       "    是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "420                                         不担忧  \n",
       "448                                         不担忧  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_use = pd.concat([df_worry,df_non_worry,df_notso_worry])\n",
    "df_use = pd.concat([df_worry,df_non_worry])\n",
    "df_use.reset_index(drop = True,inplace = True)\n",
    "df_use = df_use.reindex(np.random.permutation(df_use.index))\n",
    "df_use.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['不担忧'], dtype=object),\n",
       " array(['不担忧'], dtype=object),\n",
       " array(['不担忧'], dtype=object),\n",
       " array(['不担忧'], dtype=object),\n",
       " array(['担忧'], dtype=object)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = df_use[[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\",\"标签1（担忧对象）\",\n",
    "#                   \"标签2（担忧什么）\",\"标签3（什么保险）\",\"标签4（症状）\"]]\n",
    "labels = df_use[[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]]\n",
    "labels = np.array(labels)\n",
    "labels = list(labels)\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labels)\n",
    "labels = mlb.transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['不担忧', '担忧'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mlb.classes_.shape)\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = process.word_cut(df_use[\"博文\"])\n",
    "x_train = process.frequency(x_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给字符编码。如果x_train中的词语不在传入的实参token_index中，那么就编码为-1\n",
    "x_train = process.recoding(x_train,process.word_index)\n",
    "# x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = process.delete(x_train)\n",
    "# x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 50)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from keras import preprocessing\n",
    "\n",
    "max_len = 50\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen = max_len)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>\\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>\\n                    #天气与心情# 2月14曰，这天大家应该都记得，...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    博文  \\\n",
       "420  \\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...   \n",
       "448  \\n                    #天气与心情# 2月14曰，这天大家应该都记得，...   \n",
       "\n",
       "    是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "420                                         不担忧  \n",
       "448                                         不担忧  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420   -1\n",
       "448   -1\n",
       "588   -1\n",
       "617   -1\n",
       "183    1\n",
       "Name: 是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train = labels\n",
    "y_train = df_use[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]\n",
    "y_train = y_train.apply(lambda v: -1 if v == \"不担忧\" else 1)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(654, 50)\n",
      "(654, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape(len(y_train),1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>\\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>\\n                    #天气与心情# 2月14曰，这天大家应该都记得，...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>\\n                    555可以换新置顶惹十月底是114斤 但是我没有...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>\\n                    父母这样的爱情，我该怎么办？ ​​​      ...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>\\n                    每天心塞，会不会得病 2长春 ​        ...</td>\n",
       "      <td>担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>刚刚收到公司行政部的短信调查，问我感冒咳嗽好了没。啊啊啊，好害怕回去上班！路上好危险，要搭地...</td>\n",
       "      <td>担忧</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    博文  \\\n",
       "420  \\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...   \n",
       "448  \\n                    #天气与心情# 2月14曰，这天大家应该都记得，...   \n",
       "588  \\n                    555可以换新置顶惹十月底是114斤 但是我没有...   \n",
       "617  \\n                    父母这样的爱情，我该怎么办？ ​​​      ...   \n",
       "183  \\n                    每天心塞，会不会得病 2长春 ​        ...   \n",
       "269  刚刚收到公司行政部的短信调查，问我感冒咳嗽好了没。啊啊啊，好害怕回去上班！路上好危险，要搭地...   \n",
       "\n",
       "    是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "420                                         不担忧  \n",
       "448                                         不担忧  \n",
       "588                                         不担忧  \n",
       "617                                         不担忧  \n",
       "183                                          担忧  \n",
       "269                                          担忧  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 50, 300)           6000000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 40)                51360     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 6,051,401\n",
      "Trainable params: 6,051,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Embedding,LSTM,Bidirectional,Dropout\n",
    "\n",
    "max_features = 20000\n",
    "max_len = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,300,input_length = max_len,mask_zero = True)) # 遇到0，就不会反向传播更新权重\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(20),merge_mode = 'concat'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "# model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.compile(optimizer = 'rmsprop',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4593, 12729,   198, ...,  1574,  7798,  1947],\n",
       "       [    0,     0,     0, ...,  1052,  7798,  1947],\n",
       "       [ 2678,   118,  2340, ...,    15,  7798,  1947],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   875,    54,  4502],\n",
       "       [    0,     0,     0, ...,  3202,  7798,  1947],\n",
       "       [    0,     0,     0, ..., 17377,   947, 17377]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 457 samples, validate on 197 samples\n",
      "Epoch 1/10\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.0875 - val_loss: 0.0948 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "457/457 [==============================] - 1s 1ms/step - loss: 0.0328 - accuracy: 0.0000e+00 - val_loss: -0.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -0.2001 - accuracy: 0.0022 - val_loss: -0.3265 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -0.3735 - accuracy: 0.0000e+00 - val_loss: -0.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -0.5033 - accuracy: 0.0022 - val_loss: -0.5777 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -0.6875 - accuracy: 0.0044 - val_loss: -0.7598 - val_accuracy: 0.0051\n",
      "Epoch 7/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -0.9098 - accuracy: 0.0219 - val_loss: -0.8788 - val_accuracy: 0.0406\n",
      "Epoch 8/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -1.1041 - accuracy: 0.0481 - val_loss: -1.1251 - val_accuracy: 0.0660\n",
      "Epoch 9/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -1.3348 - accuracy: 0.0722 - val_loss: -1.1538 - val_accuracy: 0.0711\n",
      "Epoch 10/10\n",
      "457/457 [==============================] - 1s 2ms/step - loss: -1.5866 - accuracy: 0.1094 - val_loss: -1.4151 - val_accuracy: 0.1218\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs = 10,\n",
    "                    batch_size = 128, # batch_size越大越好，但是太大会影响计算效率\n",
    "                    validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['不担忧', '担忧'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>\\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>\\n                    #天气与心情# 2月14曰，这天大家应该都记得，...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>\\n                    555可以换新置顶惹十月底是114斤 但是我没有...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>\\n                    父母这样的爱情，我该怎么办？ ​​​      ...</td>\n",
       "      <td>不担忧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>\\n                    每天心塞，会不会得病 2长春 ​        ...</td>\n",
       "      <td>担忧</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    博文  \\\n",
       "420  \\n                    微博最近总推送一些讲婆媳关系的，看了之后发现婆媳...   \n",
       "448  \\n                    #天气与心情# 2月14曰，这天大家应该都记得，...   \n",
       "588  \\n                    555可以换新置顶惹十月底是114斤 但是我没有...   \n",
       "617  \\n                    父母这样的爱情，我该怎么办？ ​​​      ...   \n",
       "183  \\n                    每天心塞，会不会得病 2长春 ​        ...   \n",
       "\n",
       "    是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "420                                         不担忧  \n",
       "448                                         不担忧  \n",
       "588                                         不担忧  \n",
       "617                                         不担忧  \n",
       "183                                          担忧  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51409125, 0.48590872],\n",
       "       [0.40319288, 0.59680706],\n",
       "       [0.40424305, 0.595757  ],\n",
       "       ...,\n",
       "       [0.37255877, 0.6274412 ],\n",
       "       [0.50576293, 0.49423707],\n",
       "       [0.480347  , 0.519653  ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"Bi-LSTM(加入预训练的词向量库,多标签问题).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户名</th>\n",
       "      <th>博文</th>\n",
       "      <th>预测是否担忧（1=担忧，0=不担忧）</th>\n",
       "      <th>转发数</th>\n",
       "      <th>评论数</th>\n",
       "      <th>点赞数</th>\n",
       "      <th>发文时间</th>\n",
       "      <th>来自</th>\n",
       "      <th>页面网址</th>\n",
       "      <th>博文链接</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>玥玥的碎花小裙儿</td>\n",
       "      <td>今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021年啊...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        2019年12月31日 23:52\\n ...</td>\n",
       "      <td>realme Q 四摄迅猛龙</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E6%258B%2585%25E5...</td>\n",
       "      <td>https://weibo.com/6275719793/Innh3oI0n?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>海里星星16687</td>\n",
       "      <td>今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021啊好...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        2019年12月31日 23:35\\n ...</td>\n",
       "      <td>OPPO超视野全面屏R15</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E6%258B%2585%25E5...</td>\n",
       "      <td>https://weibo.com/6607786597/InnadlLNd?refer_f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         用户名                                                 博文  \\\n",
       "0   玥玥的碎花小裙儿  今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021年啊...   \n",
       "1  海里星星16687  今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021啊好...   \n",
       "\n",
       "   预测是否担忧（1=担忧，0=不担忧） 转发数 评论数 点赞数  \\\n",
       "0                   0               \n",
       "1                   0               \n",
       "\n",
       "                                                发文时间              来自  \\\n",
       "0  \\n                        2019年12月31日 23:52\\n ...  realme Q 四摄迅猛龙   \n",
       "1  \\n                        2019年12月31日 23:35\\n ...   OPPO超视野全面屏R15   \n",
       "\n",
       "                                                页面网址  \\\n",
       "0  https://s.weibo.com/weibo/%25E6%258B%2585%25E5...   \n",
       "1  https://s.weibo.com/weibo/%25E6%258B%2585%25E5...   \n",
       "\n",
       "                                                博文链接  \n",
       "0  https://weibo.com/6275719793/Innh3oI0n?refer_f...  \n",
       "1  https://weibo.com/6607786597/InnadlLNd?refer_f...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(\"未标记的担忧咋办标签.csv\")\n",
    "new_data_preserved = new_data\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文\n",
       "0  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...\n",
       "1  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data[[\"博文\"]]\n",
    "new_data[\"博文\"] = process.word_cut(new_data[\"博文\"])\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文\n",
       "0  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...\n",
       "1  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"博文\"] = process.frequency(new_data[\"博文\"],5)\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文\n",
       "0  [-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -...\n",
       "1  [-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"博文\"] = process.recoding(new_data[\"博文\"],process.word_index)\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "new_data[\"博文\"] = process.delete(new_data[\"博文\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = preprocessing.sequence.pad_sequences(new_data[\"博文\"],maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 3076,   15, 3624],\n",
       "       [   0,    0,    0, ..., 4344, 3076, 3624],\n",
       "       [   0,    0,    0, ..., 3076,   15, 3624],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  647, 7798, 1947],\n",
       "       [   0,    0,    0, ..., 3624,  365,  293],\n",
       "       [   0,    0,    0, ..., 3676, 2966,  871]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2014, 24)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x_test)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45977056, 0.28872412, 0.02617878, ..., 0.030577  , 0.06931883,\n",
       "        0.03858814],\n",
       "       [0.4635804 , 0.28818887, 0.02732673, ..., 0.0326975 , 0.07673627,\n",
       "        0.04089916],\n",
       "       [0.45977056, 0.28872412, 0.02617878, ..., 0.030577  , 0.06931883,\n",
       "        0.03858814],\n",
       "       ...,\n",
       "       [0.46569923, 0.4161151 , 0.0130426 , ..., 0.02122244, 0.09131664,\n",
       "        0.03654969],\n",
       "       [0.48502225, 0.3567925 , 0.0218946 , ..., 0.03336206, 0.05748242,\n",
       "        0.04534882],\n",
       "       [0.513146  , 0.3083522 , 0.01959834, ..., 0.03350639, 0.06523269,\n",
       "        0.04500294]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.reshape(prediction.shape[0],prediction.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['不担忧',\n",
       " '中性',\n",
       " '亲人',\n",
       " '作息不规律',\n",
       " '健康',\n",
       " '健康保险',\n",
       " '孩子',\n",
       " '宠物',\n",
       " '宠物保险',\n",
       " '少儿保险',\n",
       " '工作问题',\n",
       " '情绪问题',\n",
       " '意外',\n",
       " '意外保险',\n",
       " '担忧',\n",
       " '无',\n",
       " '日常习惯问题',\n",
       " '死亡保险',\n",
       " '父母',\n",
       " '经济',\n",
       " '自己',\n",
       " '营业中断',\n",
       " '营业中断险',\n",
       " '身体问题']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = pd.DataFrame(list(prediction),new_data_preserved[\"博文\"])\n",
    "Result.columns = list(mlb.classes_)\n",
    "Result = Result.reset_index() \n",
    "Result.to_excel(\"Bi-LSTM预测结果（多标签问题）.xlsx\",header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
