{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class market():\n",
    "    def word_cut(self,documents):\n",
    "        stopwords = self.stopwords\n",
    "        import jieba\n",
    "        texts = []\n",
    "        for line in documents:\n",
    "            words = ' '.join(jieba.cut(line)).split(' ') # 用空格去连接，连接后马上又拆分\n",
    "            text = []\n",
    "            for word in words:\n",
    "                if (word not in stopwords) & (word != '')& (word != '\\u3000')& (word != '\\n')&(word != '\\u200b'):\n",
    "                    text.append(word)\n",
    "            texts.append(text)\n",
    "        self.docLength = len(documents)\n",
    "        return(texts)\n",
    "    def get_docLength(self):\n",
    "        return(self.docLength)\n",
    "    def frequency(self,texts,freq):\n",
    "        from collections import defaultdict\n",
    "        frequency = defaultdict(int) # value为int\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                frequency[word] += 1\n",
    "        texts = [[word for word in text if frequency[word] > freq] for text in texts]\n",
    "        return(texts)\n",
    "    def regroup(self,texts):\n",
    "        new_texts = []\n",
    "        for i,sentence in enumerate(texts):\n",
    "            new_texts.append(\" \".join(sentence))\n",
    "        return(new_texts)\n",
    "    def add_stopwords(self,path):\n",
    "        stopwords = set()\n",
    "        with open(path,'r',encoding = 'cp936') as file:\n",
    "            for line in file:\n",
    "                stopwords.add(line.strip())\n",
    "        self.stopwords = stopwords\n",
    "        print(\"Load %s stopwords\" %len(stopwords))\n",
    "    def dictionary(self,docs):\n",
    "        token_index ={}\n",
    "        for sample in docs:\n",
    "            for word in sample:\n",
    "                if word not in token_index:\n",
    "                    token_index[word] = len(token_index) + 1\n",
    "        return(token_index)\n",
    "    def count(self,docs):\n",
    "        token_length ={}\n",
    "        for sample in docs:\n",
    "            for word in sample:\n",
    "                if word not in token_length:\n",
    "                    token_length[word] = 1\n",
    "                else:\n",
    "                    token_length[word] += 1\n",
    "        return(token_length)\n",
    "    def recoding(self,docs,token_index):\n",
    "        for i,sample in enumerate(docs):\n",
    "            for j,word in enumerate(sample):\n",
    "                if word not in token_index:\n",
    "                    sample[j] = -1\n",
    "                else:\n",
    "                    sample[j] = token_index[word]\n",
    "            docs[i] = sample\n",
    "        return(docs)\n",
    "    def delete(self,docs):\n",
    "        for index in range(len(docs)):\n",
    "            for i in range(len(docs[index])-1,-1,-1):\n",
    "                if docs[index][i] == -1:\n",
    "                    docs[index].pop(i)\n",
    "        return docs\n",
    "    def random_pick(self,df,n):\n",
    "        import random\n",
    "        import numpy as np\n",
    "        rand = np.arange(0,(len(df)-1),1)\n",
    "        random.shuffle(rand)\n",
    "        rand = list(rand[:n])\n",
    "        df = df.loc[rand,]\n",
    "        return(df)\n",
    "    def read_vectors(self,path, topn):  # read top n word vectors, i.e. top is 10000\n",
    "        lines_num, dim = 0, 0\n",
    "        vectors = {}\n",
    "        iw = []\n",
    "        wi = {}\n",
    "        with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "            first_line = True\n",
    "            for line in f:\n",
    "                if first_line:\n",
    "                    first_line = False\n",
    "                    dim = int(line.rstrip().split()[1]) # 删除向量末尾的空格，然后以空格拆分获得向量\n",
    "                    continue\n",
    "                lines_num += 1\n",
    "                tokens = line.rstrip().split(' ')\n",
    "                vectors[tokens[0]] = np.asarray([float(x) for x in tokens[1:]])# 当数据源是ndarray时，asarray不会占用新的内存；当数据源不是ndarray,asarray与array一样\n",
    "                iw.append(tokens[0]) # iw储存了所有的tokons[0]，意思是index_word\n",
    "                if topn != 0 and lines_num >= topn:\n",
    "                    break\n",
    "        for i, w in enumerate(iw):\n",
    "            wi[w] = i # wi是iw的反转，意思是word_index,用w来储存字符，用一个integer去给字符编码\n",
    "        self.dim = dim\n",
    "        self.max_words = topn\n",
    "        self.word_index = wi\n",
    "        self.index_word = iw\n",
    "        self.vectors = vectors\n",
    "        print(\"Load %s word vectors.\" % len(vectors))\n",
    "    def embedding_matrix(self):\n",
    "        embedding_matrix = np.zeros((self.max_words,self.dim))\n",
    "        for word,i in self.word_index.items():\n",
    "            if i < self.max_words:\n",
    "                embedding_vector = self.vectors.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    def navie_knn(self,dataSet, query, k):  \n",
    "        # 计算出某一样本与所有样本的距离，选择最大(应该修改为最小？)的k个样本作为用于knn\n",
    "        numSamples = dataSet.shape[0] # return row(sample) number of dataset\n",
    "\n",
    "        ## step 1: calculate Euclidean distance  \n",
    "        diff = np.tile(query, (numSamples, 1)) - dataSet #tile: 把query这个向量纵向复制，使得结果与dataset具有同样的行数\n",
    "        squaredDiff = diff ** 2  \n",
    "        squaredDist = np.sum(squaredDiff, axis = 1) # sum is performed by row  \n",
    "\n",
    "        ## step 2: sort the distance  \n",
    "        sortedDistIndices = np.argsort(squaredDist)   # numpy.argsort 返回的是数组值从小到大的索引值（注意是索引值，不是绝对值）\n",
    "        if k > len(sortedDistIndices):  \n",
    "            k = len(sortedDistIndices)  \n",
    "\n",
    "        return sortedDistIndices[0:k]\n",
    "    # build a big graph (normalized weight matrix)  \n",
    "    def buildGraph(self,MatX, kernel_type, rbf_sigma = None, knn_num_neighbors = None):  \n",
    "        num_samples = MatX.shape[0]  # return row(sample) number of MatX\n",
    "        affinity_matrix = np.zeros((num_samples, num_samples), np.float32)  \n",
    "        if kernel_type == 'rbf':  \n",
    "            if rbf_sigma == None:  \n",
    "                raise ValueError('You should input a sigma of rbf kernel!')  \n",
    "            for i in range(num_samples):  \n",
    "                row_sum = 0.0  \n",
    "                for j in range(num_samples):  \n",
    "                    diff = MatX[i, :] - MatX[j, :]  \n",
    "                    affinity_matrix[i][j] = np.exp(sum(diff**2) / (-2.0 * rbf_sigma**2))  \n",
    "                    row_sum += affinity_matrix[i][j]  \n",
    "                affinity_matrix[i][:] /= row_sum  \n",
    "        elif kernel_type == 'knn':  \n",
    "            if knn_num_neighbors == None:  \n",
    "                raise ValueError('You should input a k of knn kernel!')  \n",
    "            for i in range(num_samples):  \n",
    "                k_neighbors = self.navie_knn(MatX, MatX[i, :], knn_num_neighbors)  \n",
    "                affinity_matrix[i][k_neighbors] = 1.0 / knn_num_neighbors  # 将节点i与附近的k个节点连接起来，每个边的权重是1/knn_num_neighbors\n",
    "        else:  \n",
    "            raise NameError('Not support kernel type! You can use knn or rbf!')  \n",
    "\n",
    "        return affinity_matrix  \n",
    "    # label propagation  \n",
    "    def labelPropagation(self,Mat_Label, Mat_Unlabel, labels, kernel_type = 'rbf', rbf_sigma = 0.20, \\\n",
    "                        knn_num_neighbors = 10, max_iter = 500, tol = 1e-3):  \n",
    "        # initialize  \n",
    "        num_label_samples = Mat_Label.shape[0]  #已经标记的sample number\n",
    "        num_unlabel_samples = Mat_Unlabel.shape[0]  #未标记的sample number\n",
    "        num_samples = num_label_samples + num_unlabel_samples\n",
    "        labels_list = np.unique(labels)  #有哪些label\n",
    "        num_classes = len(labels_list)  #label的种类数\n",
    "\n",
    "        MatX = np.vstack((Mat_Label, Mat_Unlabel))\n",
    "        clamp_data_label = np.zeros((num_label_samples, num_classes), np.float32)  \n",
    "        for i in range(num_label_samples):  \n",
    "            clamp_data_label[i][labels[i]] = 1.0   #标记出每一个labelled sample的具体label是什么\n",
    "\n",
    "        label_function = np.zeros((num_samples, num_classes), np.float32)  \n",
    "        label_function[0 : num_label_samples] = clamp_data_label  \n",
    "        label_function[num_label_samples : num_samples] = -1  \n",
    "\n",
    "        # graph construction  \n",
    "        affinity_matrix = self.buildGraph(MatX, kernel_type, rbf_sigma, knn_num_neighbors)  \n",
    "\n",
    "        # start to propagation  \n",
    "        iter = 0; pre_label_function = np.zeros((num_samples, num_classes), np.float32)  \n",
    "        changed = np.abs(pre_label_function - label_function).sum()  \n",
    "        while iter < max_iter and changed > tol:  \n",
    "            if iter % 1 == 0:  \n",
    "                print (\"---> Iteration %d/%d, changed: %f\" % (iter, max_iter, changed))\n",
    "            pre_label_function = label_function  \n",
    "            iter += 1  \n",
    "\n",
    "            # propagation  \n",
    "            label_function = np.dot(affinity_matrix, label_function)  \n",
    "\n",
    "            # clamp  \n",
    "            label_function[0 : num_label_samples] = clamp_data_label  \n",
    "\n",
    "            # check converge  \n",
    "            changed = np.abs(pre_label_function - label_function).sum()  \n",
    "\n",
    "        # get terminate label of unlabeled data  \n",
    "        unlabel_data_labels = np.zeros(num_unlabel_samples)  \n",
    "        for i in range(num_unlabel_samples):  \n",
    "            unlabel_data_labels[i] = np.argmax(label_function[i+num_label_samples]) #取出参数中元素最大值所对应的索引 \n",
    "\n",
    "        return unlabel_data_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 2316 stopwords\n",
      "Load 10000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "process = market()\n",
    "process.add_stopwords(\"D:/Users/PYTHON/Precision-Marketing/stopwords.txt\")\n",
    "process.read_vectors(\"D:/NLP/sgns.target.word-word.dynwin5.thr10.neg5.dim300.txt\",10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = process.embedding_matrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共读取了10个sheet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户名</th>\n",
       "      <th>博文</th>\n",
       "      <th>关键词</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "      <th>标签1（担忧对象）</th>\n",
       "      <th>标签2（担忧什么）</th>\n",
       "      <th>标签3（什么保险）</th>\n",
       "      <th>标签4（症状）</th>\n",
       "      <th>转发数</th>\n",
       "      <th>评论数</th>\n",
       "      <th>点赞数</th>\n",
       "      <th>发文时间</th>\n",
       "      <th>来自</th>\n",
       "      <th>页面网址</th>\n",
       "      <th>博文链接</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1杯冰牛奶</td>\n",
       "      <td>\\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天06:16\\n           ...</td>\n",
       "      <td>iPhone 11</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/6606022745/IwQhN1EAC?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>干杯老铁</td>\n",
       "      <td>\\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天06:02\\n           ...</td>\n",
       "      <td>即刻笔记</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/3394404550/IwQbUFIBq?refer_f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     用户名                                                 博文    关键词  \\\n",
       "0  1杯冰牛奶  \\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...  父母怎么办   \n",
       "1   干杯老铁  \\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...  父母怎么办   \n",
       "\n",
       "   是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症） 标签1（担忧对象） 标签2（担忧什么） 标签3（什么保险）  \\\n",
       "0                                           -1       NaN       NaN       NaN   \n",
       "1                                            0       NaN       NaN       NaN   \n",
       "\n",
       "  标签4（症状） 转发数 评论数 点赞数                                               发文时间  \\\n",
       "0     NaN              \\n                        今天06:16\\n           ...   \n",
       "1     NaN              \\n                        今天06:02\\n           ...   \n",
       "\n",
       "          来自                                               页面网址  \\\n",
       "0  iPhone 11  https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "1       即刻笔记  https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "\n",
       "                                                博文链接  \n",
       "0  https://weibo.com/6606022745/IwQhN1EAC?refer_f...  \n",
       "1  https://weibo.com/3394404550/IwQbUFIBq?refer_f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"D:/Users/PYTHON/Precision-Marketing\")\n",
    "df = pd.DataFrame()\n",
    "num = 0\n",
    "for i in range(10):\n",
    "    df_temp = pd.read_excel(\"关键词标签.xlsx\",sheet_name = i)\n",
    "    df = df.append(df_temp)\n",
    "    num += 1\n",
    "print(\"一共读取了{}个sheet\".format(num))\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1576\n",
      "1576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户名</th>\n",
       "      <th>博文</th>\n",
       "      <th>关键词</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "      <th>标签1（担忧对象）</th>\n",
       "      <th>标签2（担忧什么）</th>\n",
       "      <th>标签3（什么保险）</th>\n",
       "      <th>标签4（症状）</th>\n",
       "      <th>转发数</th>\n",
       "      <th>评论数</th>\n",
       "      <th>点赞数</th>\n",
       "      <th>发文时间</th>\n",
       "      <th>来自</th>\n",
       "      <th>页面网址</th>\n",
       "      <th>博文链接</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1杯冰牛奶</td>\n",
       "      <td>\\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天06:16\\n           ...</td>\n",
       "      <td>iPhone 11</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/6606022745/IwQhN1EAC?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>干杯老铁</td>\n",
       "      <td>\\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...</td>\n",
       "      <td>父母怎么办</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        今天06:02\\n           ...</td>\n",
       "      <td>即刻笔记</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...</td>\n",
       "      <td>https://weibo.com/3394404550/IwQbUFIBq?refer_f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     用户名                                                 博文    关键词  \\\n",
       "0  1杯冰牛奶  \\n                    一直在各个公开场合严肃说了要理智告诉粉丝应该怎样...  父母怎么办   \n",
       "1   干杯老铁  \\n                    网友求助: “因为男友我感染了hpv，尿道炎，宫...  父母怎么办   \n",
       "\n",
       "   是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症） 标签1（担忧对象） 标签2（担忧什么） 标签3（什么保险）  \\\n",
       "0                                           -1       NaN       NaN       NaN   \n",
       "1                                            0       NaN       NaN       NaN   \n",
       "\n",
       "  标签4（症状） 转发数 评论数 点赞数                                               发文时间  \\\n",
       "0     NaN              \\n                        今天06:16\\n           ...   \n",
       "1     NaN              \\n                        今天06:02\\n           ...   \n",
       "\n",
       "          来自                                               页面网址  \\\n",
       "0  iPhone 11  https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "1       即刻笔记  https://s.weibo.com/weibo/%25E7%2588%25B6%25E6...   \n",
       "\n",
       "                                                博文链接  \n",
       "0  https://weibo.com/6606022745/IwQhN1EAC?refer_f...  \n",
       "1  https://weibo.com/3394404550/IwQbUFIBq?refer_f...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.concat([WORRY,PATIENT]) # concat之后row index会重复\n",
    "# df = pd.concat([PATIENT])\n",
    "# df.reset_index(drop = True,inplace = True)\n",
    "print(len(df))\n",
    "df = df.loc[pd.notna(df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]),]\n",
    "print(len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    942\n",
       " 1    329\n",
       " 0    296\n",
       " 2      9\n",
       "Name: 是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "329\n"
     ]
    }
   ],
   "source": [
    "df_worry = df[df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] == 1]\n",
    "df_worry.reset_index(drop = True,inplace = True)\n",
    "df_non_worry = df[df[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] == -1]\n",
    "df_non_worry.reset_index(drop = True,inplace = True)\n",
    "df_non_worry = process.random_pick(df_non_worry,min(len(df_worry),len(df_non_worry)))\n",
    "print(len(df_worry))\n",
    "print(len(df_non_worry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worry = df_worry[[\"博文\",\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]]\n",
    "df_non_worry = df_non_worry[[\"博文\",\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                    抑郁症我有慢性疾病，怎么治都治不好，可是我才1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                    最近不好的事情真的太多了 想逃避所有情绪不稳定的...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n                    突然好怕自己有一天撑不住怎么办，父母怎么办，还有...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n                    疫情发生之后，觉悟到有个好身体的重要性，养成良好...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n                    皮肤病狗狗。喂了2天，看到我就屁颠屁颠跑过来…实...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>\\n                    生产后一切安好，没掉发没腰痛没怕冷…直到最近腰不...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>\\n                    坐着不知道该做什么，连续两天毫无食欲。节目完了之...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>\\n                    当一天的24小时里，你只有4、5个小时的片段式睡...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>\\n                    #小九与小胡同学的日常#   76day小胡同学...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>\\n                    1、最近上牙的第三切牙旁边的肉好像发炎了，连带着...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    博文  \\\n",
       "0    \\n                    抑郁症我有慢性疾病，怎么治都治不好，可是我才1...   \n",
       "1    \\n                    最近不好的事情真的太多了 想逃避所有情绪不稳定的...   \n",
       "2    \\n                    突然好怕自己有一天撑不住怎么办，父母怎么办，还有...   \n",
       "3    \\n                    疫情发生之后，觉悟到有个好身体的重要性，养成良好...   \n",
       "4    \\n                    皮肤病狗狗。喂了2天，看到我就屁颠屁颠跑过来…实...   \n",
       "..                                                 ...   \n",
       "324  \\n                    生产后一切安好，没掉发没腰痛没怕冷…直到最近腰不...   \n",
       "325  \\n                    坐着不知道该做什么，连续两天毫无食欲。节目完了之...   \n",
       "326  \\n                    当一天的24小时里，你只有4、5个小时的片段式睡...   \n",
       "327  \\n                    #小九与小胡同学的日常#   76day小胡同学...   \n",
       "328  \\n                    1、最近上牙的第三切牙旁边的肉好像发炎了，连带着...   \n",
       "\n",
       "     是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "0                                              1  \n",
       "1                                              1  \n",
       "2                                              1  \n",
       "3                                              1  \n",
       "4                                              1  \n",
       "..                                           ...  \n",
       "324                                            1  \n",
       "325                                            1  \n",
       "326                                            1  \n",
       "327                                            1  \n",
       "328                                            1  \n",
       "\n",
       "[329 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_worry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>\\n                    比莫干吃了一惊：“淳国知道大合萨的行程？” “他...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>\\n                    麻药过后是漫长的疼痛╯﹏╰冷漠的护士让我不是很开...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>#英语，学起来！##2月21日可以查四六级成绩# 【TED演讲：走出“舒适区”】“2015年...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>\\n                    梦见坐在教室里上课，实木的桌子好像有点豪华。梦见...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>\\n                    越大越觉得做一个普通人，有人疼有人爱，生病能正常...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>\\n                    一粒药12块钱 比我在学校吃一顿饭还贵(天坛新院...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>\\n                    【家庭婚姻情感专题】 问答(2020.03.01...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>\\n                    今天探索了维他的港式奶茶 还行8我真的每天吃完晚...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>\\n                    1、早孕期（12周之前）子宫还没有出盆腔，就是说...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>\\n                    抑郁症我可以不吃药了吗 因为肺炎在家没药了三天...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    博文  \\\n",
       "256  \\n                    比莫干吃了一惊：“淳国知道大合萨的行程？” “他...   \n",
       "161  \\n                    麻药过后是漫长的疼痛╯﹏╰冷漠的护士让我不是很开...   \n",
       "561  #英语，学起来！##2月21日可以查四六级成绩# 【TED演讲：走出“舒适区”】“2015年...   \n",
       "491  \\n                    梦见坐在教室里上课，实木的桌子好像有点豪华。梦见...   \n",
       "365  \\n                    越大越觉得做一个普通人，有人疼有人爱，生病能正常...   \n",
       "..                                                 ...   \n",
       "183  \\n                    一粒药12块钱 比我在学校吃一顿饭还贵(天坛新院...   \n",
       "85   \\n                    【家庭婚姻情感专题】 问答(2020.03.01...   \n",
       "869  \\n                    今天探索了维他的港式奶茶 还行8我真的每天吃完晚...   \n",
       "840  \\n                    1、早孕期（12周之前）子宫还没有出盆腔，就是说...   \n",
       "219  \\n                    抑郁症我可以不吃药了吗 因为肺炎在家没药了三天...   \n",
       "\n",
       "     是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "256                                           -1  \n",
       "161                                           -1  \n",
       "561                                           -1  \n",
       "491                                           -1  \n",
       "365                                           -1  \n",
       "..                                           ...  \n",
       "183                                           -1  \n",
       "85                                            -1  \n",
       "869                                           -1  \n",
       "840                                           -1  \n",
       "219                                           -1  \n",
       "\n",
       "[329 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_worry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "329\n",
      "329\n",
      "329\n"
     ]
    }
   ],
   "source": [
    "print(len(df_worry))\n",
    "print(len(df_non_worry))\n",
    "df_worry = df_worry.dropna()\n",
    "df_non_worry = df_non_worry.dropna()\n",
    "print(len(df_worry))\n",
    "print(len(df_non_worry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>\\n                    #孝感地震#08年汶川8级地震那次，正坐在上铺床...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>\\n                    最近又在关注暗网的信息，觉得好可怕。想想在国外独...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>\\n                    没有太多感情基础的婚姻最终都是以吵架度日吗？当父...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>\\n                    我能理解孩子病了家长不愿意带孩子往医院跑的心情，...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>\\n                    Q最近因为出不了门，大人小孩都很烦躁，我也经常失...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    博文  \\\n",
       "336  \\n                    #孝感地震#08年汶川8级地震那次，正坐在上铺床...   \n",
       "210  \\n                    最近又在关注暗网的信息，觉得好可怕。想想在国外独...   \n",
       "467  \\n                    没有太多感情基础的婚姻最终都是以吵架度日吗？当父...   \n",
       "537  \\n                    我能理解孩子病了家长不愿意带孩子往医院跑的心情，...   \n",
       "401  \\n                    Q最近因为出不了门，大人小孩都很烦躁，我也经常失...   \n",
       "\n",
       "     是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）  \n",
       "336                                           -1  \n",
       "210                                            1  \n",
       "467                                           -1  \n",
       "537                                           -1  \n",
       "401                                           -1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use = pd.concat([df_worry,df_non_worry])\n",
    "df_use.reset_index(drop = True,inplace = True)\n",
    "df_use = df_use.reindex(np.random.permutation(df_use.index))\n",
    "df_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = process.word_cut(df_use[\"博文\"])\n",
    "x_train = process.frequency(x_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_index = process.dictionary(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length = process.count(x_train)\n",
    "token_length = {key:token_length[key] for key in sorted(token_length,key = lambda x: token_length[x],reverse = True)[:round((2/5)*len(token_index))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给字符编码。如果x_train中的词语不在传入的实参token_index中，那么就编码为-1\n",
    "x_train = process.recoding(x_train,process.word_index)\n",
    "# x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = process.delete(x_train)\n",
    "# x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, 50)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from keras import preprocessing\n",
    "\n",
    "max_len = 50\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen = max_len)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\n",
       "336                                            0\n",
       "210                                            1\n",
       "467                                            0\n",
       "537                                            0\n",
       "401                                            0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_use[[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"]]\n",
    "y_train[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"] = y_train[\"是否担忧（1=担忧，-1=完全不担忧，0=中性，有些担忧但不用买保险,2=疑似抑郁症）\"].apply(lambda v: 0 if v == -1 else 1)\n",
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in = len(y_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape(y_in)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658, 50)\n",
      "(658,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大的序号是： 828\n"
     ]
    }
   ],
   "source": [
    "def get_values(token_index):\n",
    "    values = []\n",
    "    for key in token_index:\n",
    "        values.append(token_index[key])\n",
    "    return(values)\n",
    "values = get_values(token_index)\n",
    "values[:5]\n",
    "print(\"最大的序号是：\",max(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 50, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 40)                51360     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,051,401\n",
      "Trainable params: 3,051,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Embedding,LSTM,Bidirectional,Dropout,Conv1D,MaxPooling1D\n",
    "\n",
    "max_features = 10000\n",
    "max_len = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,300,input_length = max_len,mask_zero = True)) # 遇到0，就不会反向传播更新权重\n",
    "# model.add(Embedding(max_features,300,input_length = max_len))\n",
    "# model.add(Conv1D(32, 5, activation='relu'))\n",
    "# model.add(MaxPooling1D(5))\n",
    "# model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(20),merge_mode = 'concat'))\n",
    "model.add(Dense(1,activation = 'sigmoid')) # softmax其实本质上扩展后的sigmoid\n",
    "model.compile(optimizer = 'rmsprop',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 460 samples, validate on 198 samples\n",
      "Epoch 1/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.6868 - accuracy: 0.5304 - val_loss: 0.6515 - val_accuracy: 0.6414\n",
      "Epoch 2/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.6228 - accuracy: 0.7043 - val_loss: 0.6209 - val_accuracy: 0.6869\n",
      "Epoch 3/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.6009 - accuracy: 0.7109 - val_loss: 0.6405 - val_accuracy: 0.6010\n",
      "Epoch 4/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.5772 - accuracy: 0.7370 - val_loss: 0.5937 - val_accuracy: 0.6919\n",
      "Epoch 5/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7652 - val_loss: 0.5841 - val_accuracy: 0.6919\n",
      "Epoch 6/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.5105 - accuracy: 0.7935 - val_loss: 0.5676 - val_accuracy: 0.7525\n",
      "Epoch 7/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.4811 - accuracy: 0.8065 - val_loss: 0.6213 - val_accuracy: 0.6414\n",
      "Epoch 8/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.4511 - accuracy: 0.8130 - val_loss: 0.6192 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.4179 - accuracy: 0.8348 - val_loss: 0.5590 - val_accuracy: 0.7172\n",
      "Epoch 10/10\n",
      "460/460 [==============================] - 1s 1ms/step - loss: 0.3888 - accuracy: 0.8522 - val_loss: 0.6682 - val_accuracy: 0.6313\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs = 10,\n",
    "                    batch_size = 128, # batch_size越大越好，但是太大会影响计算效率\n",
    "                    validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"Bi-LSTM(加入预训练的词向量库).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户名</th>\n",
       "      <th>博文</th>\n",
       "      <th>预测是否担忧（1=担忧，0=不担忧）</th>\n",
       "      <th>转发数</th>\n",
       "      <th>评论数</th>\n",
       "      <th>点赞数</th>\n",
       "      <th>发文时间</th>\n",
       "      <th>来自</th>\n",
       "      <th>页面网址</th>\n",
       "      <th>博文链接</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>玥玥的碎花小裙儿</td>\n",
       "      <td>今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021年啊...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        2019年12月31日 23:52\\n ...</td>\n",
       "      <td>realme Q 四摄迅猛龙</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E6%258B%2585%25E5...</td>\n",
       "      <td>https://weibo.com/6275719793/Innh3oI0n?refer_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>海里星星16687</td>\n",
       "      <td>今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021啊好...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\n                        2019年12月31日 23:35\\n ...</td>\n",
       "      <td>OPPO超视野全面屏R15</td>\n",
       "      <td>https://s.weibo.com/weibo/%25E6%258B%2585%25E5...</td>\n",
       "      <td>https://weibo.com/6607786597/InnadlLNd?refer_f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         用户名                                                 博文  \\\n",
       "0   玥玥的碎花小裙儿  今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021年啊...   \n",
       "1  海里星星16687  今晚就要跨年了咋办呢？先迈左脚还是右脚啊？跨不过去会不会摔一跤？腿太长会不会跨到2021啊好...   \n",
       "\n",
       "   预测是否担忧（1=担忧，0=不担忧） 转发数 评论数 点赞数  \\\n",
       "0                   0               \n",
       "1                   0               \n",
       "\n",
       "                                                发文时间              来自  \\\n",
       "0  \\n                        2019年12月31日 23:52\\n ...  realme Q 四摄迅猛龙   \n",
       "1  \\n                        2019年12月31日 23:35\\n ...   OPPO超视野全面屏R15   \n",
       "\n",
       "                                                页面网址  \\\n",
       "0  https://s.weibo.com/weibo/%25E6%258B%2585%25E5...   \n",
       "1  https://s.weibo.com/weibo/%25E6%258B%2585%25E5...   \n",
       "\n",
       "                                                博文链接  \n",
       "0  https://weibo.com/6275719793/Innh3oI0n?refer_f...  \n",
       "1  https://weibo.com/6607786597/InnadlLNd?refer_f...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(\"未标记的担忧咋办标签.csv\")\n",
    "new_data_preserved = new_data\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文\n",
       "0  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...\n",
       "1  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data[[\"博文\"]]\n",
    "new_data[\"博文\"] = process.word_cut(new_data[\"博文\"])\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文\n",
       "0  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,...\n",
       "1  [今晚, 跨年, 咋办, 先迈, 左脚, 右脚, 跨, 摔, 一跤, 腿, 太长会, 跨到,..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"博文\"] = process.frequency(new_data[\"博文\"],5)\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>博文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  博文\n",
       "0  [-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -...\n",
       "1  [-1, -1, -1, -1, -1, -1, 4344, -1, -1, 3076, -..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"博文\"] = process.recoding(new_data[\"博文\"],process.word_index)\n",
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "new_data[\"博文\"] = process.delete(new_data[\"博文\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = preprocessing.sequence.pad_sequences(new_data[\"博文\"],maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03170225, 0.04756665, 0.03170225, ..., 0.02784744, 0.23346764,\n",
       "       0.03607011], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x_test)\n",
    "prediction = prediction.reshape(len(prediction))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = pd.DataFrame({\"预测结果\":list(prediction),\"博文\":new_data_preserved[\"博文\"]})\n",
    "# Result.to_excel(\"Bi-LSTM预测结果（(加入预训练的词向量库)）.xlsx\",header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
